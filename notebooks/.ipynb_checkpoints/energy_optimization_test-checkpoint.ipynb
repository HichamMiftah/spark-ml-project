{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Energy Optimization Goals\n",
    "\n",
    "This notebook demonstrates how to test each goal from our energy optimization project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "First, let's import required libraries and create our Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "import json\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "# Create Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Energy Optimization Analysis\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 1: Identifier des opportunités d'optimisation énergétique\n",
    "\n",
    "Let's test the energy optimization identification by creating sample data and running our analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create sample data\n",
    "sample_data = [\n",
    "    # High consumption during peak hours\n",
    "    (\"2025-01-20 14:00:00\", 1, 180.0, 24.0, 60.0, 50, 1, 14),\n",
    "    # High temperature scenario\n",
    "    (\"2025-01-20 14:05:00\", 1, 140.0, 28.0, 65.0, 45, 1, 14),\n",
    "    # Low occupancy scenario\n",
    "    (\"2025-01-20 14:10:00\", 1, 120.0, 22.0, 55.0, 10, 1, 14)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "schema = StructType([\n",
    "    StructField(\"timestamp\", StringType(), True),\n",
    "    StructField(\"building_id\", IntegerType(), True),\n",
    "    StructField(\"energy_consumption\", DoubleType(), True),\n",
    "    StructField(\"temperature\", DoubleType(), True),\n",
    "    StructField(\"humidity\", DoubleType(), True),\n",
    "    StructField(\"occupancy\", IntegerType(), True),\n",
    "    StructField(\"day_of_week\", IntegerType(), True),\n",
    "    StructField(\"hour_of_day\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "df = spark.createDataFrame(sample_data, schema)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 2: Proposer des recommandations\n",
    "\n",
    "Now let's test the recommendation generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def generate_recommendations(df):\n",
    "    return df.withColumn(\"recommendations\",\n",
    "        when((col(\"hour_of_day\").between(9, 17)) & (col(\"energy_consumption\") > 150),\n",
    "            \"High consumption during peak hours: 1) Adjust HVAC settings 2) Schedule high-energy tasks for off-peak hours 3) Implement automated lighting controls\") \\\n",
    "        .when((col(\"temperature\") > 25) & (col(\"energy_consumption\") > 130),\n",
    "            \"High energy use with high temperature: 1) Optimize cooling system efficiency 2) Install solar shading 3) Use natural ventilation when possible\") \\\n",
    "        .when((col(\"occupancy\") < 30) & (col(\"energy_consumption\") > 100),\n",
    "            \"High energy use with low occupancy: 1) Implement motion sensors 2) Reduce base load 3) Audit always-on equipment\") \\\n",
    "        .otherwise(\"Energy consumption within normal parameters\"))\n",
    "\n",
    "# Generate recommendations\n",
    "recommendations_df = generate_recommendations(df)\n",
    "recommendations_df.select(\"timestamp\", \"energy_consumption\", \"temperature\", \"occupancy\", \"recommendations\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal 3: Simuler la provenance de données en temps réels\n",
    "\n",
    "Let's test the real-time data simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def create_energy_data():\n",
    "    \"\"\"Generate simulated energy consumption data\"\"\"\n",
    "    current_time = datetime.now()\n",
    "    \n",
    "    data = {\n",
    "        'timestamp': current_time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'building_id': random.randint(1, 10),\n",
    "        'energy_consumption': random.uniform(50, 200),\n",
    "        'temperature': random.uniform(15, 35),\n",
    "        'humidity': random.uniform(30, 80),\n",
    "        'occupancy': random.randint(0, 100),\n",
    "        'day_of_week': current_time.weekday(),\n",
    "        'hour_of_day': current_time.hour\n",
    "    }\n",
    "    return data\n",
    "\n",
    "# Generate sample real-time data\n",
    "sample_realtime_data = [create_energy_data() for _ in range(5)]\n",
    "\n",
    "# Create DataFrame from real-time data\n",
    "realtime_df = spark.createDataFrame([row for row in sample_realtime_data])\n",
    "realtime_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Complete System\n",
    "\n",
    "Now let's analyze the real-time data and generate recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate recommendations for real-time data\n",
    "realtime_recommendations = generate_recommendations(realtime_df)\n",
    "\n",
    "# Show results\n",
    "realtime_recommendations.select(\n",
    "    \"timestamp\", \n",
    "    \"building_id\",\n",
    "    \"energy_consumption\",\n",
    "    \"temperature\",\n",
    "    \"occupancy\",\n",
    "    \"recommendations\"\n",
    ").show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing Results\n",
    "\n",
    "The above tests demonstrate:\n",
    "1. Energy optimization opportunity identification\n",
    "2. Automated recommendation generation\n",
    "3. Real-time data simulation and processing\n",
    "\n",
    "You can modify the test data values to see different recommendations based on:\n",
    "- Peak hours (9 AM - 5 PM)\n",
    "- Temperature thresholds\n",
    "- Occupancy levels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
